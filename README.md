# RoboticGrasping
Autonomous Vision-based Robotic Grasping of Household Objects: A Practical Case Study


## Abstract
Autonomous robotic grasping has emerged as a valuable capability for automating everyday household tasks like table bossing, cleaning, and meal prep ration. Still, accurately detecting and manipulating diverse everyday objects in unstructured home environments remains a significant challenge. In this study, an integrated robotic system combining YOLOv8x-seg deep learning for real-time object detection and segmentation with computer vision techniques to determine optimal grasping points is proposed. A custom dataset of over 1000 images containing common household objects was created, with manual annotation and augmentation to train the YOLOv8x-seg segmentation model. The approach processes input images to understand desired arrangements and identify target objects and their locations for grasping. The detected objects are localized using camera calibration and aligned with estimated orientations from OpenCV models. Extensive tests have proven that representative household objects in cluttered arrangements have a grasping success rate of over $90\%$ using a 3-DOF Delta Parallel robot with a 2-finger gripper guided entirely by visual perception. By overcoming real-world challenges like transparent and reflective materials, the perception-guided robots provide precise and efficient robotic grasping in unstructured home environments. This integrated approach combines robust perception and localization, providing promising evidence for reliable automation of repetitive household organization tasks.

