{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asalroudbari/RoboticGrasping/blob/main/YOLOV8Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfefd72-b292-4ad2-c18c-82ca1d2a1d84"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7EYRZqhyp7m",
        "outputId": "373ca6c0-7886-4c56-99fd-d329a91ed46a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "o6UbjDroy_CV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv8 ðŸš€ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir ."
      ],
      "metadata": {
        "id": "ktegpM42AooT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b42ad8f-0fe7-4989-b1d0-79d5ede27f27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m559.7/559.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.1/510.1 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPlease paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "tppIjYZi5H_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uhCWy4A9PUC",
        "outputId": "9f7fa58d-c913-4d6d-addb-fd27e84098cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"KdyzhxZx8EoSBwkDqpaO\")\n",
        "project = rf.workspace(\"taarlab-e2cvo\").project(\"utensilgrasp\")\n",
        "dataset = project.version(3).download(\"yolov8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3F_eS4Be5Hng",
        "outputId": "9a1dc372-7dc3-4480-fd92-1761d9c36ac5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.4-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.13.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.4)\n",
            "Collecting wget (from roboflow)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.42.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.2.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (4.8.0.76)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.10.1)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=9f80b0aff301c4c18423350438b12c791f7bd68f0945f9f9f44021e2eff3e263\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "Successfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.4 supervision-0.13.0 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.134 is required but found version=8.0.166, to fix: `pip install ultralytics==8.0.134`\n",
            "Downloading Dataset Version Zip in UtensilGrasp-3 to yolov8: 100% [22696876 / 22696876] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to UtensilGrasp-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1528/1528 [00:00<00:00, 2751.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Freeze Layers"
      ],
      "metadata": {
        "id": "8dNusVHk5MQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_layer(trainer):\n",
        "    model = trainer.model\n",
        "    num_freeze = 10\n",
        "    print(f\"Freezing {num_freeze} layers\")\n",
        "    freeze = [f'model.{x}.' for x in range(num_freeze)]  # layers to freeze\n",
        "    for k, v in model.named_parameters():\n",
        "        v.requires_grad = True  # train all layers\n",
        "        if any(x in k for x in freeze):\n",
        "            print(f'freezing {k}')\n",
        "            v.requires_grad = False\n",
        "    print(f\"{num_freeze} layers are freezed.\")"
      ],
      "metadata": {
        "id": "roOaPjUc49zK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhWxoeWd-dcW",
        "outputId": "d3a92f50-a116-41c5-f363-e81c9fc749b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat {dataset.location}/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7VM0-aNuF-O",
        "outputId": "a2c24452-9ac9-48aa-d34a-f454e8039f9b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- bottle\n",
            "- layed bottle\n",
            "- metal box\n",
            "- metal fork\n",
            "- metal spoon\n",
            "- pfork\n",
            "- pglass\n",
            "- pknife\n",
            "- pspoon\n",
            "- sause\n",
            "- square plate\n",
            "nc: 11\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: utensilgrasp\n",
            "  url: https://universe.roboflow.com/taarlab-e2cvo/utensilgrasp/dataset/3\n",
            "  version: 3\n",
            "  workspace: taarlab-e2cvo\n",
            "test: /content/datasets/UtensilGrasp-3/test/images\n",
            "train: /content/datasets/UtensilGrasp-3/train/images\n",
            "val: /content/datasets/UtensilGrasp-3/valid/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "metadata": {
        "id": "PLTREICLueQF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## detection"
      ],
      "metadata": {
        "id": "v72oxtym6nXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=train model=yolov8x.pt data={dataset.location}/data.yaml freeze = 10 epochs=25 imgsz=640 plots=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91eeXZtu2syx",
        "outputId": "48899f7f-af08-4074-c080-67a6933bd84c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/content/datasets/UtensilGrasp-3/data.yaml, epochs=25, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "Overriding model.yaml nc=80 with nc=11\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8728561  ultralytics.nn.modules.head.Detect           [11, [320, 640, 640]]         \n",
            "Model summary: 365 layers, 68163201 parameters, 68163185 gradients\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.5.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.5.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.5.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.5.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.5.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.5.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.4.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.4.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.4.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.4.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.4.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.4.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.5.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.5.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.5.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.5.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.5.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.5.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/UtensilGrasp-3/train/labels.cache... 621 images, 0 backgrounds, 0 corrupt: 100% 621/621 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/UtensilGrasp-3/valid/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100% 68/68 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/25      5.07G      0.514      2.446     0.9602         39        640: 100% 39/39 [00:28<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.21s/it]\n",
            "                   all         68         90      0.545      0.751      0.526      0.457\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/25      5.22G     0.5978      1.379      1.019         39        640: 100% 39/39 [00:27<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         68         90      0.636      0.881      0.872      0.728\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/25       5.3G     0.6109      1.029      1.004         30        640: 100% 39/39 [00:27<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                   all         68         90      0.723      0.896      0.929      0.762\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/25      5.64G      0.614     0.9087       1.01         30        640: 100% 39/39 [00:28<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         68         90      0.898      0.816       0.93       0.74\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/25      5.27G     0.6486     0.8359      1.034         24        640: 100% 39/39 [00:28<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.39it/s]\n",
            "                   all         68         90      0.787      0.919      0.922      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/25      5.25G     0.5866     0.7838      1.002         27        640: 100% 39/39 [00:28<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                   all         68         90      0.847      0.953      0.962      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/25      5.24G     0.5513     0.6735     0.9938         19        640: 100% 39/39 [00:29<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         68         90      0.883      0.961      0.972      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/25      5.25G     0.5335     0.6238     0.9856         29        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                   all         68         90      0.847       0.95      0.959      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/25      5.26G     0.5415     0.6186     0.9783         27        640: 100% 39/39 [00:28<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.29it/s]\n",
            "                   all         68         90      0.908      0.922      0.962      0.863\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/25      5.29G     0.5243     0.5915     0.9822         29        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                   all         68         90      0.947      0.931      0.969       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/25      5.27G     0.4964     0.5447     0.9607         37        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         68         90      0.955      0.976      0.988      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/25      5.24G     0.4839     0.5376     0.9632         40        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         68         90       0.89      0.978      0.968      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/25      5.27G      0.469     0.5093     0.9425         23        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.39it/s]\n",
            "                   all         68         90       0.88      0.967       0.98       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/25      5.12G     0.4679     0.4951     0.9377         44        640: 100% 39/39 [00:29<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                   all         68         90      0.961      0.977      0.987      0.929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/25      5.27G     0.4557     0.4704     0.9332         21        640: 100% 39/39 [00:28<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n",
            "                   all         68         90      0.941      0.993      0.987      0.924\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/25      5.21G     0.4044     0.3816      0.946         22        640: 100% 39/39 [00:29<00:00,  1.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.28it/s]\n",
            "                   all         68         90      0.963      0.986      0.983      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/25      5.25G     0.4117     0.3778     0.9661         13        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.26it/s]\n",
            "                   all         68         90      0.932      0.966      0.964      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/25      5.14G     0.3851     0.3544     0.9242         13        640: 100% 39/39 [00:28<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.31it/s]\n",
            "                   all         68         90      0.939      0.985      0.978      0.938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/25      5.27G     0.3995     0.3251      0.955         13        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                   all         68         90      0.963      0.973      0.985      0.939\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/25      5.26G      0.359     0.3244     0.9312         30        640: 100% 39/39 [00:28<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         68         90       0.96      0.982      0.988      0.948\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/25      5.25G     0.3477     0.3069     0.9197         21        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.39it/s]\n",
            "                   all         68         90      0.976       0.97      0.982      0.952\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/25      5.12G     0.3408     0.2867     0.9004         20        640: 100% 39/39 [00:28<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.28it/s]\n",
            "                   all         68         90      0.971      0.978      0.984      0.944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/25      5.64G     0.3365     0.2717     0.9128         21        640: 100% 39/39 [00:28<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.40it/s]\n",
            "                   all         68         90      0.959      0.987      0.979      0.958\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/25      5.25G     0.3116     0.2741     0.9124         22        640: 100% 39/39 [00:28<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.25it/s]\n",
            "                   all         68         90      0.962      0.991      0.975      0.953\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/25      5.26G     0.2911     0.2448     0.8763         22        640: 100% 39/39 [00:28<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.06s/it]\n",
            "                   all         68         90      0.955      0.992       0.97      0.951\n",
            "\n",
            "25 epochs completed in 0.262 hours.\n",
            "Optimizer stripped from runs/detect/train3/weights/last.pt, 136.7MB\n",
            "Optimizer stripped from runs/detect/train3/weights/best.pt, 136.7MB\n",
            "\n",
            "Validating runs/detect/train3/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 268 layers, 68134161 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.08s/it]\n",
            "                   all         68         90      0.959      0.987      0.979      0.958\n",
            "                bottle         68          5          1          1      0.995      0.995\n",
            "          layed bottle         68          7      0.974          1      0.995      0.963\n",
            "             metal box         68          8      0.985          1      0.995      0.995\n",
            "            metal fork         68          4      0.776          1      0.945      0.917\n",
            "           metal spoon         68          6          1       0.97      0.995      0.995\n",
            "                 pfork         68         14      0.979          1      0.995      0.969\n",
            "                pglass         68          6      0.967          1      0.995      0.995\n",
            "                pknife         68         13          1       0.89      0.935      0.896\n",
            "                pspoon         68         14      0.921          1      0.934      0.884\n",
            "                 sause         68          7      0.971          1      0.995      0.982\n",
            "          square plate         68          6      0.973          1      0.995       0.95\n",
            "Speed: 3.7ms preprocess, 25.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=val model=/content/runs/detect/train3/weights/best.pt data={dataset.location}/data.yaml imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIGFIHV6-cbS",
        "outputId": "d12cd220-658d-4b43-8351-fbdd5fe6cdfa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 268 layers, 68134161 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/UtensilGrasp-3/valid/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100% 68/68 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:07<00:00,  1.43s/it]\n",
            "                   all         68         90      0.958      0.987      0.979      0.958\n",
            "                bottle         68          5          1          1      0.995      0.995\n",
            "          layed bottle         68          7      0.974          1      0.995      0.963\n",
            "             metal box         68          8      0.985          1      0.995      0.995\n",
            "            metal fork         68          4      0.775          1      0.945      0.917\n",
            "           metal spoon         68          6          1      0.969      0.995      0.995\n",
            "                 pfork         68         14      0.979          1      0.995      0.969\n",
            "                pglass         68          6      0.966          1      0.995      0.995\n",
            "                pknife         68         13          1      0.892      0.935      0.887\n",
            "                pspoon         68         14      0.921          1      0.934      0.884\n",
            "                 sause         68          7      0.971          1      0.995      0.982\n",
            "          square plate         68          6      0.972          1      0.995      0.961\n",
            "Speed: 8.3ms preprocess, 67.3ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/runs/detect/train3/weights/best.pt conf= 0.1 source=/content/datasets/UtensilGrasp-3/test/images imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMqC9MVJ_ZC3",
        "outputId": "a8660625-00fb-4f1d-c370-a7bf3b4b06eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 268 layers, 68134161 parameters, 0 gradients\n",
            "\n",
            "image 1/69 /content/datasets/UtensilGrasp-3/test/images/11_jpg.rf.2d6d63813ed3f0a2d3e218ed82316b76.jpg: 640x640 3 pforks, 3 pknifes, 3 pspoons, 81.6ms\n",
            "image 2/69 /content/datasets/UtensilGrasp-3/test/images/13_jpg.rf.805b04bbca957eea6cb4c56177e0e903.jpg: 640x640 3 pforks, 3 pknifes, 3 pspoons, 1 square plate, 58.3ms\n",
            "image 3/69 /content/datasets/UtensilGrasp-3/test/images/17_jpg.rf.1d2e7b39ed7b23054b8948d46a44f8b5.jpg: 640x640 3 pforks, 3 pknifes, 3 pspoons, 1 square plate, 58.3ms\n",
            "image 4/69 /content/datasets/UtensilGrasp-3/test/images/4_jpg.rf.8b00b5b3a2ac906c341605064e64993b.jpg: 640x640 3 pforks, 2 pknifes, 4 pspoons, 1 square plate, 53.8ms\n",
            "image 5/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6731_JPG.rf.d29a61608a2d892bcde889598c135715.jpg: 640x640 1 pknife, 53.9ms\n",
            "image 6/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6733_JPG.rf.e464593830a124d82e6d549ff3d224d8.jpg: 640x640 1 pknife, 53.3ms\n",
            "image 7/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6737_JPG.rf.c643710dfd06b282da251b1342222bbb.jpg: 640x640 1 pknife, 52.4ms\n",
            "image 8/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6745_JPG.rf.c3edb0fba9cf50e902c414192aeccf58.jpg: 640x640 1 pknife, 1 pspoon, 52.2ms\n",
            "image 9/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6750_JPG.rf.55263f67408f98545aa81029ed66f01d.jpg: 640x640 1 pknife, 52.9ms\n",
            "image 10/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6759_JPG.rf.f0880508d288b993226622881ce53386.jpg: 640x640 1 pfork, 1 pknife, 54.0ms\n",
            "image 11/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6762_JPG.rf.21497ad59c14c98c2121ea8ce6b8fd15.jpg: 640x640 1 pspoon, 53.8ms\n",
            "image 12/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6763_JPG.rf.bcbaf84d1ba84711a9b056d238524d8a.jpg: 640x640 1 pspoon, 52.5ms\n",
            "image 13/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6775_JPG.rf.755620e5acd1a3cc0394148a4729540a.jpg: 640x640 1 pspoon, 54.7ms\n",
            "image 14/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6777_JPG.rf.50d7739fefd3c51596ade2f8fdd71445.jpg: 640x640 1 pspoon, 53.1ms\n",
            "image 15/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6783_JPG.rf.922f4025120732e5f4602466b88f2d98.jpg: 640x640 1 pspoon, 54.6ms\n",
            "image 16/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6789_JPG.rf.f9baed9d8e5c99ef8ef111effe5881f5.jpg: 640x640 1 pspoon, 56.1ms\n",
            "image 17/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6800_JPG.rf.1ee27a59c0738506a084ab4c8a08e7dd.jpg: 640x640 1 pfork, 55.0ms\n",
            "image 18/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6801_JPG.rf.eb7f0dc70bafc382517ee8437dd973c3.jpg: 640x640 1 pfork, 56.3ms\n",
            "image 19/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6804_JPG.rf.a528476345a4e7d8adc76af24c4d376a.jpg: 640x640 1 pfork, 55.0ms\n",
            "image 20/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6808_JPG.rf.28a77eb50359e27025c821fbc1b96571.jpg: 640x640 1 pfork, 54.7ms\n",
            "image 21/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6816_JPG.rf.2aa88c01af1b1a8e2ee5c3d74636bb84.jpg: 640x640 1 pfork, 55.1ms\n",
            "image 22/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6817_JPG.rf.58843feefd54a91eed2ba1e6f3c32695.jpg: 640x640 1 pfork, 55.2ms\n",
            "image 23/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6836_JPG.rf.4a6426b1d8d8710c1613219d51a91703.jpg: 640x640 1 pglass, 53.7ms\n",
            "image 24/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6838_JPG.rf.91b22113716ff5a73a156c35c060fb3e.jpg: 640x640 1 pglass, 54.7ms\n",
            "image 25/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6850_JPG.rf.91c409ccd61b2db31a86fb4754201e42.jpg: 640x640 1 metal fork, 1 pglass, 54.0ms\n",
            "image 26/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6905_JPG.rf.14124bcfd2d820722a3dd078ffe17ebd.jpg: 640x640 1 pglass, 54.8ms\n",
            "image 27/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6907_JPG.rf.cd35fba897dec67be441fccb42462201.jpg: 640x640 1 pglass, 55.5ms\n",
            "image 28/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6908_JPG.rf.c384598362ee319c89c36ec187139b6d.jpg: 640x640 1 metal fork, 1 pglass, 54.8ms\n",
            "image 29/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6915_JPG.rf.ba3ed90fe362b4322961f49f9d7fa598.jpg: 640x640 1 metal box, 54.8ms\n",
            "image 30/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6916_JPG.rf.21e0bf693bd1ac73b79eb4688f4f9ba2.jpg: 640x640 1 metal box, 54.8ms\n",
            "image 31/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6920_JPG.rf.ebe10ff8305dc1c85e3c23bfe0db1580.jpg: 640x640 1 metal box, 54.8ms\n",
            "image 32/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6926_JPG.rf.d0b077a4ef50890d956cadeaffedd44b.jpg: 640x640 1 metal box, 55.2ms\n",
            "image 33/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6929_JPG.rf.696860fc4292a89f9ab90064510c34a2.jpg: 640x640 1 metal box, 54.5ms\n",
            "image 34/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6935_JPG.rf.f27f3702200624263fe6296af4b07f35.jpg: 640x640 1 metal box, 53.6ms\n",
            "image 35/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6941_JPG.rf.139afc40ccf88a5afc8f876f197580c1.jpg: 640x640 1 metal box, 1 metal spoon, 56.1ms\n",
            "image 36/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6949_JPG.rf.3dcbbc73400412a006fed3a6334d97d3.jpg: 640x640 1 sause, 53.9ms\n",
            "image 37/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6957_JPG.rf.bca4a1d22a363da1a02e57a05e369908.jpg: 640x640 1 sause, 55.4ms\n",
            "image 38/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6960_JPG.rf.d65488c1f5d8c13c8485d68683417daa.jpg: 640x640 1 sause, 54.2ms\n",
            "image 39/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6966_JPG.rf.fe6176b991a345ca80a2465912c139bd.jpg: 640x640 1 sause, 55.4ms\n",
            "image 40/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6979_JPG.rf.e3b793ba45d132e257f2d71b89c27a26.jpg: 640x640 1 sause, 54.8ms\n",
            "image 41/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6981_JPG.rf.c62db4e9f1fe7b9dca0c46bab9342fe9.jpg: 640x640 1 metal fork, 2 sauses, 54.4ms\n",
            "image 42/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6987_JPG.rf.62b136ff5a0e5f902fbd426df7bead4d.jpg: 640x640 1 bottle, 55.1ms\n",
            "image 43/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6990_JPG.rf.6dca91ba298cb8ef643fcb791a604e9b.jpg: 640x640 1 bottle, 55.4ms\n",
            "image 44/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6992_JPG.rf.d6211a9ec330a8338d10c1eb96c886f3.jpg: 640x640 1 bottle, 56.3ms\n",
            "image 45/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6993_JPG.rf.4688e13705cc456c8c1148d381362310.jpg: 640x640 1 bottle, 55.2ms\n",
            "image 46/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6995_JPG.rf.923d487c8e34f638e092fc8bbd876f57.jpg: 640x640 1 bottle, 55.7ms\n",
            "image 47/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7011_JPG.rf.3664507eb1b1697b5abfa6d7bb3ec272.jpg: 640x640 1 layed bottle, 55.0ms\n",
            "image 48/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7023_JPG.rf.9a50d71317dd2ccd112650e6a7c1eb53.jpg: 640x640 1 layed bottle, 55.7ms\n",
            "image 49/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7027_JPG.rf.1822b3a49a31b92b7d817debf051c332.jpg: 640x640 1 layed bottle, 55.3ms\n",
            "image 50/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7031_JPG.rf.b4aeb4d4445ec752fb99ceecd896dc1b.jpg: 640x640 1 layed bottle, 55.7ms\n",
            "image 51/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7037_JPG.rf.4387ecb3a29f2798814bb0886d6bd6a3.jpg: 640x640 1 layed bottle, 55.1ms\n",
            "image 52/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7046_JPG.rf.8f8ed0a1968a8d03f86bbbbdd9d1a603.jpg: 640x640 1 layed bottle, 54.4ms\n",
            "image 53/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7048_JPG.rf.86338492a5569b2415f347159470089c.jpg: 640x640 1 layed bottle, 53.8ms\n",
            "image 54/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7049_JPG.rf.cacec1f66640a3d5ca7d96a7197589c0.jpg: 640x640 1 square plate, 55.5ms\n",
            "image 55/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7059_JPG.rf.9d1e2364ad4ebb8ce07a1e44702150b1.jpg: 640x640 1 square plate, 54.8ms\n",
            "image 56/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7066_JPG.rf.d89b4964e1197f2f16eebb1d83e18b54.jpg: 640x640 1 square plate, 55.2ms\n",
            "image 57/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7075_JPG.rf.61b8f7338ebec54ecacc500ec7ebece1.jpg: 640x640 1 square plate, 55.9ms\n",
            "image 58/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7076_JPG.rf.f822cd8ad44595a69e4df60219867c24.jpg: 640x640 1 square plate, 54.5ms\n",
            "image 59/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7108_JPG.rf.3f152ebd409137f4c1db7a57236f8f81.jpg: 640x640 1 metal spoon, 54.9ms\n",
            "image 60/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7110_JPG.rf.46318995b7d806ef58195d6aabb9b3ff.jpg: 640x640 1 metal spoon, 55.0ms\n",
            "image 61/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7117_JPG.rf.fd4e61462ff61820c38de5bc8ac680b1.jpg: 640x640 1 metal spoon, 56.4ms\n",
            "image 62/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7121_JPG.rf.8e69b9285289e3af07de8720baac560b.jpg: 640x640 1 metal fork, 1 metal spoon, 53.5ms\n",
            "image 63/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7126_JPG.rf.b6e120c9c5ae4d1480c75cc4699c5404.jpg: 640x640 1 metal spoon, 56.2ms\n",
            "image 64/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7132_JPG.rf.53429b12634e6c07929037f1deb8f935.jpg: 640x640 1 metal spoon, 54.7ms\n",
            "image 65/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7141_JPG.rf.1eba0ae890498e04cc3cd9dd27b3868c.jpg: 640x640 1 metal fork, 55.7ms\n",
            "image 66/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7153_JPG.rf.cfda2ba7aec27237ea017b8f3a2343ff.jpg: 640x640 1 metal fork, 54.7ms\n",
            "image 67/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7159_JPG.rf.c068d0dc69e07962593053238c7e58ef.jpg: 640x640 1 metal fork, 55.2ms\n",
            "image 68/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7160_JPG.rf.7547931a5c3ceab6770989e0e82bf7ab.jpg: 640x640 1 metal fork, 55.6ms\n",
            "image 69/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7162_JPG.rf.8e041c33927fb17797a7747bb885f627.jpg: 640x640 2 metal forks, 56.4ms\n",
            "Speed: 1.5ms preprocess, 55.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## segmentation"
      ],
      "metadata": {
        "id": "wMgW9GNP6re3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=segment mode=train model=yolov8x-seg.pt  data={dataset.location}/data.yaml freeze = 12 epochs=30 imgsz=640"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqV5xSiF6rIY",
        "outputId": "cb72a5f9-b09f-4c17-9131-3ef5bfec5293"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x-seg.pt to 'yolov8x-seg.pt'...\n",
            "100% 137M/137M [00:19<00:00, 7.54MB/s]\n",
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8x-seg.pt, data=/content/datasets/UtensilGrasp-3/data.yaml, epochs=30, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=12, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train2\n",
            "Overriding model.yaml nc=80 with nc=11\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1  12326801  ultralytics.nn.modules.head.Segment          [11, 32, 320, [320, 640, 640]]\n",
            "YOLOv8x-seg summary: 401 layers, 71761441 parameters, 71761425 gradients\n",
            "\n",
            "Transferred 651/657 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.5.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.5.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.5.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.5.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.5.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.5.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.3.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.3.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.4.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.4.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.4.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.4.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.4.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.4.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.5.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.5.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.5.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.5.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.5.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.5.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.2.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.2.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.2.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.2.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.2.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.2.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/UtensilGrasp-3/train/labels.cache... 621 images, 0 backgrounds, 0 corrupt: 100% 621/621 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/UtensilGrasp-3/valid/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100% 68/68 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/segment/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 106 weight(decay=0.0), 117 weight(decay=0.0005), 116 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/30      7.41G     0.5048     0.7431      2.342     0.9544         39        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.04s/it]\n",
            "                   all         68         90      0.587      0.924      0.834      0.693      0.574      0.912      0.811      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/30      7.69G     0.6123     0.7844      1.351      1.022         39        640: 100% 39/39 [00:39<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.03it/s]\n",
            "                   all         68         90      0.506       0.88       0.84      0.699      0.705      0.704      0.785      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/30      7.64G     0.6382     0.7401      1.087      1.015         30        640: 100% 39/39 [00:40<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.08s/it]\n",
            "                   all         68         90      0.759       0.91       0.85      0.743      0.759       0.91       0.85      0.739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/30      8.25G     0.6017      0.742      0.934     0.9998         30        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.09s/it]\n",
            "                   all         68         90      0.853      0.928      0.933      0.797      0.853      0.928      0.933      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/30      7.67G     0.6247      0.686       0.87      1.016         24        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.04s/it]\n",
            "                   all         68         90      0.801      0.948       0.93      0.816      0.801      0.948       0.93      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/30      7.61G     0.6117     0.6391     0.8125     0.9928         27        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all         68         90       0.84      0.948      0.974      0.847       0.84      0.948      0.974      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/30      7.54G      0.551     0.6115     0.6906     0.9776         19        640: 100% 39/39 [00:41<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.09s/it]\n",
            "                   all         68         90      0.828      0.948      0.971      0.861      0.819      0.942      0.958       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/30      7.72G     0.5452     0.6459     0.6557     0.9815         29        640: 100% 39/39 [00:41<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         68         90      0.906      0.895      0.961      0.861      0.906      0.895      0.961      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/30      7.67G     0.5347     0.6388     0.6486     0.9617         27        640: 100% 39/39 [00:41<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         68         90      0.918      0.941      0.966      0.856      0.918      0.941      0.966      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/30      8.23G     0.5195     0.6185     0.5959     0.9638         29        640: 100% 39/39 [00:41<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.02s/it]\n",
            "                   all         68         90      0.932      0.931      0.968      0.899      0.932      0.931      0.968      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/30      7.74G     0.4917     0.5497     0.5562     0.9419         37        640: 100% 39/39 [00:40<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all         68         90      0.959      0.941      0.973      0.892      0.959      0.941      0.973      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/30      7.69G     0.4769      0.554     0.5329     0.9415         40        640: 100% 39/39 [00:41<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         68         90      0.964      0.941       0.98      0.912      0.964      0.941       0.98      0.883\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/30      7.77G     0.4778      0.556     0.5195     0.9481         23        640: 100% 39/39 [00:41<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         68         90      0.921      0.965      0.969      0.909      0.921      0.965      0.969      0.879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/30      8.25G     0.4683     0.5529     0.5197     0.9307         44        640: 100% 39/39 [00:40<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.01s/it]\n",
            "                   all         68         90      0.941      0.973      0.985       0.92      0.941      0.973      0.985      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/30      7.65G     0.4482     0.5595     0.4841     0.9203         21        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         68         90      0.928      0.945      0.984      0.932      0.928      0.945      0.984      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/30      7.59G     0.4444     0.5673     0.4741     0.9169         21        640: 100% 39/39 [00:40<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         68         90      0.943       0.97      0.969      0.928      0.943       0.97      0.969      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/30       7.6G     0.4238     0.5261     0.4438     0.9152         29        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.02it/s]\n",
            "                   all         68         90      0.914      0.951      0.958      0.905      0.914      0.951      0.958       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/30      7.72G     0.4459     0.5261     0.4634     0.9262         54        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         68         90      0.945      0.971      0.977      0.939      0.945      0.971      0.977        0.9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/30      7.74G     0.4278     0.5454     0.4383     0.9242         36        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.02s/it]\n",
            "                   all         68         90      0.964      0.987      0.986      0.947      0.964      0.987      0.986      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/30      7.76G     0.4081     0.5303     0.4152     0.8957         55        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.02s/it]\n",
            "                   all         68         90      0.953       0.97      0.984      0.946      0.953       0.97      0.984      0.894\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/30      7.78G     0.3497     0.4176     0.3562     0.8951         21        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.06it/s]\n",
            "                   all         68         90      0.957      0.983      0.977      0.946      0.957      0.983      0.977      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/30      7.61G     0.3404      0.422      0.328     0.8931         20        640: 100% 39/39 [00:40<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         68         90      0.966      0.956      0.984      0.959      0.966      0.956      0.984      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/30      7.59G      0.334     0.3942     0.3518      0.894         21        640: 100% 39/39 [00:42<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         68         90      0.927      0.981      0.981      0.952      0.927      0.981      0.981      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/30      7.58G     0.3131     0.3748     0.3138      0.881         22        640: 100% 39/39 [00:40<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         68         90      0.939      0.976      0.984      0.959      0.939      0.976      0.984      0.917\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/30      7.59G     0.3047     0.4121     0.3045     0.8755         21        640: 100% 39/39 [00:40<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         68         90       0.96      0.976      0.987      0.964       0.96      0.976      0.987      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/30       7.6G      0.318     0.3899       0.31     0.8934         21        640: 100% 39/39 [00:40<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         68         90      0.944      0.975      0.982      0.953      0.944      0.975      0.982        0.9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/30      7.57G     0.2911      0.384     0.2655     0.8645         20        640: 100% 39/39 [00:40<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n",
            "                   all         68         90      0.943      0.977      0.987      0.963      0.943      0.977      0.987      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/30      7.72G     0.2909     0.3882     0.2619     0.8792         13        640: 100% 39/39 [00:41<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.00s/it]\n",
            "                   all         68         90      0.969      0.962      0.982      0.955      0.969      0.962      0.982        0.9\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/30      7.78G     0.2689      0.363     0.2463     0.8599         21        640: 100% 39/39 [00:40<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                   all         68         90      0.979       0.98      0.984      0.963      0.979       0.98      0.984      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/30      7.59G     0.2614     0.3611     0.2333     0.8598         13        640: 100% 39/39 [00:40<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.63s/it]\n",
            "                   all         68         90      0.959      0.975      0.974      0.952      0.959      0.975      0.974      0.901\n",
            "\n",
            "30 epochs completed in 0.421 hours.\n",
            "Optimizer stripped from runs/segment/train2/weights/last.pt, 144.0MB\n",
            "Optimizer stripped from runs/segment/train2/weights/best.pt, 144.0MB\n",
            "\n",
            "Validating runs/segment/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8x-seg summary (fused): 295 layers, 71731249 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 3/3 [00:04<00:00,  1.39s/it]\n",
            "                   all         68         90      0.939      0.977      0.984       0.96      0.939      0.977      0.984      0.917\n",
            "                bottle         68          5      0.832          1      0.995      0.979      0.832          1      0.995      0.995\n",
            "          layed bottle         68          7       0.97          1      0.995      0.995       0.97          1      0.995      0.995\n",
            "             metal box         68          8      0.973          1      0.995      0.995      0.973          1      0.995      0.995\n",
            "            metal fork         68          4      0.793          1      0.945      0.903      0.793          1      0.945      0.814\n",
            "           metal spoon         68          6          1      0.852      0.995      0.979          1      0.852      0.995      0.943\n",
            "                 pfork         68         14          1      0.982      0.995      0.941          1      0.982      0.995      0.834\n",
            "                pglass         68          6      0.964          1      0.995      0.974      0.964          1      0.995      0.979\n",
            "                pknife         68         13          1      0.912      0.956      0.889          1      0.912      0.956      0.791\n",
            "                pspoon         68         14      0.863          1      0.962      0.927      0.863          1      0.962      0.815\n",
            "                 sause         68          7      0.972          1      0.995      0.984      0.972          1      0.995      0.956\n",
            "          square plate         68          6       0.96          1      0.995      0.995       0.96          1      0.995      0.974\n",
            "Speed: 0.2ms preprocess, 34.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=segment mode=val model=/content/runs/segment/train2/weights/best.pt data={dataset.location}/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ishr_AQEhWQ",
        "outputId": "1f84b4e3-7c85-4f98-cb88-40a9b6ecbb2b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8x-seg summary (fused): 295 layers, 71731249 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/UtensilGrasp-3/valid/labels.cache... 68 images, 0 backgrounds, 0 corrupt: 100% 68/68 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% 5/5 [00:09<00:00,  1.98s/it]\n",
            "                   all         68         90      0.939      0.976      0.984       0.96      0.939      0.976      0.984      0.917\n",
            "                bottle         68          5      0.832          1      0.995      0.995      0.832          1      0.995      0.995\n",
            "          layed bottle         68          7       0.97          1      0.995      0.995       0.97          1      0.995      0.995\n",
            "             metal box         68          8      0.973          1      0.995      0.995      0.973          1      0.995      0.995\n",
            "            metal fork         68          4      0.793          1      0.945      0.894      0.793          1      0.945      0.823\n",
            "           metal spoon         68          6          1      0.851      0.995      0.979          1      0.851      0.995      0.943\n",
            "                 pfork         68         14          1      0.974      0.995      0.941          1      0.974      0.995      0.834\n",
            "                pglass         68          6      0.964          1      0.995      0.974      0.964          1      0.995      0.979\n",
            "                pknife         68         13          1      0.913      0.956      0.889          1      0.913      0.956       0.78\n",
            "                pspoon         68         14      0.862          1      0.962      0.927      0.862          1      0.962      0.815\n",
            "                 sause         68          7      0.972          1      0.995      0.972      0.972          1      0.995      0.956\n",
            "          square plate         68          6       0.96          1      0.995      0.995       0.96          1      0.995      0.974\n",
            "Speed: 8.5ms preprocess, 83.8ms inference, 0.0ms loss, 5.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo task=segment mode=predict model=/content/runs/segment/train2/weights/best.pt conf=0.25 source=/content/datasets/UtensilGrasp-3/test/images save=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdQqjQyJEvNA",
        "outputId": "6119ee2a-0aa3-4466-814f-6444a3e1e386"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8x-seg summary (fused): 295 layers, 71731249 parameters, 0 gradients\n",
            "\n",
            "image 1/69 /content/datasets/UtensilGrasp-3/test/images/11_jpg.rf.2d6d63813ed3f0a2d3e218ed82316b76.jpg: 640x640 3 pforks, 3 pknifes, 3 pspoons, 93.6ms\n",
            "image 2/69 /content/datasets/UtensilGrasp-3/test/images/13_jpg.rf.805b04bbca957eea6cb4c56177e0e903.jpg: 640x640 3 pforks, 3 pknifes, 3 pspoons, 1 square plate, 76.0ms\n",
            "image 3/69 /content/datasets/UtensilGrasp-3/test/images/17_jpg.rf.1d2e7b39ed7b23054b8948d46a44f8b5.jpg: 640x640 3 pforks, 3 pknifes, 3 pspoons, 1 square plate, 75.6ms\n",
            "image 4/69 /content/datasets/UtensilGrasp-3/test/images/4_jpg.rf.8b00b5b3a2ac906c341605064e64993b.jpg: 640x640 3 pforks, 2 pknifes, 3 pspoons, 1 square plate, 73.1ms\n",
            "image 5/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6731_JPG.rf.d29a61608a2d892bcde889598c135715.jpg: 640x640 1 pknife, 71.3ms\n",
            "image 6/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6733_JPG.rf.e464593830a124d82e6d549ff3d224d8.jpg: 640x640 1 pknife, 74.7ms\n",
            "image 7/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6737_JPG.rf.c643710dfd06b282da251b1342222bbb.jpg: 640x640 1 pknife, 74.9ms\n",
            "image 8/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6745_JPG.rf.c3edb0fba9cf50e902c414192aeccf58.jpg: 640x640 1 pknife, 73.3ms\n",
            "image 9/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6750_JPG.rf.55263f67408f98545aa81029ed66f01d.jpg: 640x640 1 pknife, 73.9ms\n",
            "image 10/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6759_JPG.rf.f0880508d288b993226622881ce53386.jpg: 640x640 1 pknife, 74.0ms\n",
            "image 11/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6762_JPG.rf.21497ad59c14c98c2121ea8ce6b8fd15.jpg: 640x640 1 pspoon, 72.8ms\n",
            "image 12/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6763_JPG.rf.bcbaf84d1ba84711a9b056d238524d8a.jpg: 640x640 1 pspoon, 73.9ms\n",
            "image 13/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6775_JPG.rf.755620e5acd1a3cc0394148a4729540a.jpg: 640x640 1 pspoon, 76.0ms\n",
            "image 14/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6777_JPG.rf.50d7739fefd3c51596ade2f8fdd71445.jpg: 640x640 1 pspoon, 73.7ms\n",
            "image 15/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6783_JPG.rf.922f4025120732e5f4602466b88f2d98.jpg: 640x640 1 pspoon, 75.5ms\n",
            "image 16/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6789_JPG.rf.f9baed9d8e5c99ef8ef111effe5881f5.jpg: 640x640 1 pspoon, 73.5ms\n",
            "image 17/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6800_JPG.rf.1ee27a59c0738506a084ab4c8a08e7dd.jpg: 640x640 1 pfork, 75.3ms\n",
            "image 18/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6801_JPG.rf.eb7f0dc70bafc382517ee8437dd973c3.jpg: 640x640 1 pfork, 74.0ms\n",
            "image 19/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6804_JPG.rf.a528476345a4e7d8adc76af24c4d376a.jpg: 640x640 1 pfork, 75.5ms\n",
            "image 20/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6808_JPG.rf.28a77eb50359e27025c821fbc1b96571.jpg: 640x640 1 pfork, 73.2ms\n",
            "image 21/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6816_JPG.rf.2aa88c01af1b1a8e2ee5c3d74636bb84.jpg: 640x640 1 pfork, 72.6ms\n",
            "image 22/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6817_JPG.rf.58843feefd54a91eed2ba1e6f3c32695.jpg: 640x640 1 pfork, 73.4ms\n",
            "image 23/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6836_JPG.rf.4a6426b1d8d8710c1613219d51a91703.jpg: 640x640 1 pglass, 75.5ms\n",
            "image 24/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6838_JPG.rf.91b22113716ff5a73a156c35c060fb3e.jpg: 640x640 1 pglass, 74.4ms\n",
            "image 25/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6850_JPG.rf.91c409ccd61b2db31a86fb4754201e42.jpg: 640x640 1 layed bottle, 1 metal box, 1 pglass, 74.4ms\n",
            "image 26/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6905_JPG.rf.14124bcfd2d820722a3dd078ffe17ebd.jpg: 640x640 1 pglass, 74.6ms\n",
            "image 27/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6907_JPG.rf.cd35fba897dec67be441fccb42462201.jpg: 640x640 1 layed bottle, 1 metal box, 1 pglass, 73.6ms\n",
            "image 28/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6908_JPG.rf.c384598362ee319c89c36ec187139b6d.jpg: 640x640 1 metal box, 1 pglass, 74.1ms\n",
            "image 29/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6915_JPG.rf.ba3ed90fe362b4322961f49f9d7fa598.jpg: 640x640 1 metal box, 73.5ms\n",
            "image 30/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6916_JPG.rf.21e0bf693bd1ac73b79eb4688f4f9ba2.jpg: 640x640 1 metal box, 75.2ms\n",
            "image 31/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6920_JPG.rf.ebe10ff8305dc1c85e3c23bfe0db1580.jpg: 640x640 1 metal box, 73.2ms\n",
            "image 32/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6926_JPG.rf.d0b077a4ef50890d956cadeaffedd44b.jpg: 640x640 1 metal box, 73.4ms\n",
            "image 33/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6929_JPG.rf.696860fc4292a89f9ab90064510c34a2.jpg: 640x640 1 metal box, 74.7ms\n",
            "image 34/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6935_JPG.rf.f27f3702200624263fe6296af4b07f35.jpg: 640x640 1 metal box, 73.6ms\n",
            "image 35/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6941_JPG.rf.139afc40ccf88a5afc8f876f197580c1.jpg: 640x640 1 metal box, 75.5ms\n",
            "image 36/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6949_JPG.rf.3dcbbc73400412a006fed3a6334d97d3.jpg: 640x640 1 sause, 71.9ms\n",
            "image 37/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6957_JPG.rf.bca4a1d22a363da1a02e57a05e369908.jpg: 640x640 1 sause, 73.9ms\n",
            "image 38/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6960_JPG.rf.d65488c1f5d8c13c8485d68683417daa.jpg: 640x640 1 sause, 75.1ms\n",
            "image 39/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6966_JPG.rf.fe6176b991a345ca80a2465912c139bd.jpg: 640x640 1 sause, 73.6ms\n",
            "image 40/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6979_JPG.rf.e3b793ba45d132e257f2d71b89c27a26.jpg: 640x640 1 sause, 75.9ms\n",
            "image 41/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6981_JPG.rf.c62db4e9f1fe7b9dca0c46bab9342fe9.jpg: 640x640 2 sauses, 73.9ms\n",
            "image 42/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6987_JPG.rf.62b136ff5a0e5f902fbd426df7bead4d.jpg: 640x640 1 bottle, 73.6ms\n",
            "image 43/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6990_JPG.rf.6dca91ba298cb8ef643fcb791a604e9b.jpg: 640x640 1 bottle, 72.4ms\n",
            "image 44/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6992_JPG.rf.d6211a9ec330a8338d10c1eb96c886f3.jpg: 640x640 1 bottle, 75.1ms\n",
            "image 45/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6993_JPG.rf.4688e13705cc456c8c1148d381362310.jpg: 640x640 1 bottle, 74.7ms\n",
            "image 46/69 /content/datasets/UtensilGrasp-3/test/images/IMG_6995_JPG.rf.923d487c8e34f638e092fc8bbd876f57.jpg: 640x640 1 bottle, 74.4ms\n",
            "image 47/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7011_JPG.rf.3664507eb1b1697b5abfa6d7bb3ec272.jpg: 640x640 1 layed bottle, 74.4ms\n",
            "image 48/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7023_JPG.rf.9a50d71317dd2ccd112650e6a7c1eb53.jpg: 640x640 1 layed bottle, 73.2ms\n",
            "image 49/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7027_JPG.rf.1822b3a49a31b92b7d817debf051c332.jpg: 640x640 1 layed bottle, 74.2ms\n",
            "image 50/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7031_JPG.rf.b4aeb4d4445ec752fb99ceecd896dc1b.jpg: 640x640 1 layed bottle, 73.0ms\n",
            "image 51/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7037_JPG.rf.4387ecb3a29f2798814bb0886d6bd6a3.jpg: 640x640 1 layed bottle, 75.3ms\n",
            "image 52/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7046_JPG.rf.8f8ed0a1968a8d03f86bbbbdd9d1a603.jpg: 640x640 1 layed bottle, 74.7ms\n",
            "image 53/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7048_JPG.rf.86338492a5569b2415f347159470089c.jpg: 640x640 1 layed bottle, 75.3ms\n",
            "image 54/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7049_JPG.rf.cacec1f66640a3d5ca7d96a7197589c0.jpg: 640x640 1 square plate, 73.8ms\n",
            "image 55/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7059_JPG.rf.9d1e2364ad4ebb8ce07a1e44702150b1.jpg: 640x640 1 square plate, 73.5ms\n",
            "image 56/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7066_JPG.rf.d89b4964e1197f2f16eebb1d83e18b54.jpg: 640x640 1 square plate, 75.1ms\n",
            "image 57/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7075_JPG.rf.61b8f7338ebec54ecacc500ec7ebece1.jpg: 640x640 1 square plate, 73.5ms\n",
            "image 58/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7076_JPG.rf.f822cd8ad44595a69e4df60219867c24.jpg: 640x640 1 square plate, 73.8ms\n",
            "image 59/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7108_JPG.rf.3f152ebd409137f4c1db7a57236f8f81.jpg: 640x640 1 metal spoon, 74.4ms\n",
            "image 60/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7110_JPG.rf.46318995b7d806ef58195d6aabb9b3ff.jpg: 640x640 1 metal spoon, 71.4ms\n",
            "image 61/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7117_JPG.rf.fd4e61462ff61820c38de5bc8ac680b1.jpg: 640x640 1 metal spoon, 74.7ms\n",
            "image 62/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7121_JPG.rf.8e69b9285289e3af07de8720baac560b.jpg: 640x640 1 metal fork, 1 metal spoon, 74.6ms\n",
            "image 63/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7126_JPG.rf.b6e120c9c5ae4d1480c75cc4699c5404.jpg: 640x640 1 metal spoon, 72.8ms\n",
            "image 64/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7132_JPG.rf.53429b12634e6c07929037f1deb8f935.jpg: 640x640 1 metal spoon, 73.1ms\n",
            "image 65/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7141_JPG.rf.1eba0ae890498e04cc3cd9dd27b3868c.jpg: 640x640 1 metal fork, 74.0ms\n",
            "image 66/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7153_JPG.rf.cfda2ba7aec27237ea017b8f3a2343ff.jpg: 640x640 1 metal fork, 72.8ms\n",
            "image 67/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7159_JPG.rf.c068d0dc69e07962593053238c7e58ef.jpg: 640x640 1 pfork, 74.9ms\n",
            "image 68/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7160_JPG.rf.7547931a5c3ceab6770989e0e82bf7ab.jpg: 640x640 1 metal fork, 73.9ms\n",
            "image 69/69 /content/datasets/UtensilGrasp-3/test/images/IMG_7162_JPG.rf.8e041c33927fb17797a7747bb885f627.jpg: 640x640 1 metal fork, 75.5ms\n",
            "Speed: 1.5ms preprocess, 74.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### example"
      ],
      "metadata": {
        "id": "4X0QpA8TN30Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo task=segment mode=predict model=/content/runs/segment/train2/weights/best.pt conf=0.25 source='/content/datasets/UtensilGrasp-3/test/images/4_jpg.rf.8b00b5b3a2ac906c341605064e64993b.jpg' save=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuHBNPijNwt4",
        "outputId": "0d3fd99a-9b35-494b-b61a-7085719059b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics YOLOv8.0.166 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8x-seg summary (fused): 295 layers, 71731249 parameters, 0 gradients\n",
            "\n",
            "image 1/1 /content/datasets/UtensilGrasp-3/test/images/4_jpg.rf.8b00b5b3a2ac906c341605064e64993b.jpg: 640x640 3 pforks, 2 pknifes, 3 pspoons, 1 square plate, 106.0ms\n",
            "Speed: 1.9ms preprocess, 106.0ms inference, 80.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict3\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}